{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model =  InceptionV3(\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    "    weights=None\n",
    ")\n",
    "\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print the model summary  \n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('accuracy')>0.999):\n",
    "                print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(.2)(x)               \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss ='binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, 'horses') \n",
    "train_humans_dir = os.path.join(train_dir, 'humans') \n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255. \n",
    ")\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 32s 2s/step - loss: 0.5151 - accuracy: 0.8218 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.1062 - accuracy: 0.9640 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.1628 - accuracy: 0.9426 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.0481 - accuracy: 0.9864 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.0410 - accuracy: 0.9834 - val_loss: 6.5851e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0535 - accuracy: 0.9796 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.0294 - accuracy: 0.9893 - val_loss: 8.7075e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0270 - accuracy: 0.9883 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0546 - accuracy: 0.9825 - val_loss: 4.1953e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0093 - accuracy: 0.9951 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0533 - accuracy: 0.9854 - val_loss: 1.2327e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0452 - accuracy: 0.9903 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.0418 - val_accuracy: 0.9844\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0187 - accuracy: 0.9912 - val_loss: 1.1176e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0053 - accuracy: 0.9961 - val_loss: 0.0321 - val_accuracy: 0.9922\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.1398 - accuracy: 0.9844 - val_loss: 3.7464e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.0180 - val_accuracy: 0.9922\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0096 - accuracy: 0.9951 - val_loss: 0.0034 - val_accuracy: 0.9961\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 8.3434e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.0263 - val_accuracy: 0.9961\n",
      "Epoch 24/50\n",
      "16/17 [===========================>..] - ETA: 1s - loss: 0.0029 - accuracy: 1.0000\n",
      "Reached 99.9% accuracy so cancelling training!\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
